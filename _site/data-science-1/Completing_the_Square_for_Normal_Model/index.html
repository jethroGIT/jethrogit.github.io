<!DOCTYPE html>
<html>
  <head>
      <title>Completing the Square for Normal Model with Multiple Observations – Jethro Andersson Apriliano Ofe – Forgiven sinner and Student at Maranatha Christian University</title>

        <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="The subchapter 2.5 of Bayesian Data Analysis Third Edition explains how to estimate a normal mean with known variance; particularly, the subchapter extends the development of a normal model with a single observation into the more realistic situation where a sample of independent and identically distributed observations $y = (y_1, \ldots, y_n)$ are available.

$\pmb{\text{Figure 1}}$: Example of a normal distribution consisting a horde of rabbits. Image taken from Casey Dunn, some rights reserved.

The posterior density of the normal model consists of a likelihood distribution, $\Pr(y \mid \theta)$, and a prior distribution, $\Pr(\theta)$. Specifically,

\[\begin{align}
	y_i \mid \theta &amp;\sim \text{N}(\theta, \sigma^2) &amp;&amp; \text{A normal distribution with mean = }\theta \text{ and variance = }\sigma^2\text{, for }i=1, \ldots, n \\
	\theta          &amp;\sim \text{N}(\mu_0, \tau_0^2)  &amp;&amp;  \text{A normal distribution with mean = }\mu_0 \text{ and variance = }\tau_0^2.
\end{align}\]
" />
    <meta property="og:description" content="The subchapter 2.5 of Bayesian Data Analysis Third Edition explains how to estimate a normal mean with known variance; particularly, the subchapter extends the development of a normal model with a single observation into the more realistic situation where a sample of independent and identically distributed observations $y = (y_1, \ldots, y_n)$ are available.

$\pmb{\text{Figure 1}}$: Example of a normal distribution consisting a horde of rabbits. Image taken from Casey Dunn, some rights reserved.

The posterior density of the normal model consists of a likelihood distribution, $\Pr(y \mid \theta)$, and a prior distribution, $\Pr(\theta)$. Specifically,

\[\begin{align}
	y_i \mid \theta &amp;\sim \text{N}(\theta, \sigma^2) &amp;&amp; \text{A normal distribution with mean = }\theta \text{ and variance = }\sigma^2\text{, for }i=1, \ldots, n \\
	\theta          &amp;\sim \text{N}(\mu_0, \tau_0^2)  &amp;&amp;  \text{A normal distribution with mean = }\mu_0 \text{ and variance = }\tau_0^2.
\end{align}\]
" />
    
    <meta name="author" content="Jethro Andersson Apriliano Ofe" />

    
    <meta property="og:title" content="Completing the Square for Normal Model with Multiple Observations" />
    <meta property="twitter:title" content="Completing the Square for Normal Model with Multiple Observations" />
    

    <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <link rel="icon" href="/favicon.png" type="image/gif">

    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="alternate" type="application/rss+xml" title="Jethro Andersson Apriliano Ofe - Forgiven sinner and Student at Maranatha Christian University" href="/feed.xml" />

    <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
  </head>

  <body>

    <div class="vertical-center"> 
      <div class="container">
        <div class="row">
              <div id="left-bar">
                
                  <div class="col-lg-offset-1 col-lg-3 col-md-12 col-sm-12 col-xs-12 left-bar border-right">

    
        <a href="http://localhost:4000/">
            <img src="/assets/images/me-gullit-model.jpg" class="img-responsive hidden-xs hidden-sm hidden-md" alt=""/>
        </a>
    
    <h3 class="text-center">Jethro Andersson Apriliano Ofe <small></small></h3>
<!--    <p class="text-center" style="color: #707073;">Forgiven sinner and Student at Maranatha Christian University</p> -->
        <p class="text-center" style="color: #707073;"><a href="https://jethrogit.github.io/sermons/Forgive_Sinner/"><b>A Forgiven Sinner</b></a> and <a href="https://www.maranatha.edu/"><b>Student at Maranatha Christian University</b></a></p> 
    <div class="hidden-lg" style="margin-bottom:5px;">
        <p class="text-center">
            <a href="http://localhost:4000" class="color-icon" title="Home"><i class="fa fa-home" aria-hidden="true"></i></a> - 
            
<a href="mailto:jethro.andersson02@gmail.com" class="color-icon"><i class="fa fa-envelope" title="Email"></i></a>


<a href="https://github.com/jethroGIT" class="color-icon" title="Github"><i class="fa fa-github"></i></a>

<a href="https://www.linkedin.com/in/jethro-andersson-apriliano-ofe" class="color-icon" title="Linkedin"><i class="fa fa-linkedin"></i></a>



<!-- <a href="http://stackoverflow.com/users/1473726" class="color-icon" title="StacKoverflow"><i class="fa fa-stack-overflow"></i></a> -->




        </p>
    </div>
    <div class="hidden-xs hidden-sm hidden-md" style="margin-bottom:5px;">
        <hr >

        
        <i class="fa fa-github fw"></i><a href="https://github.com/jethroGIT"> github.com/jethroGIT</a>    <br />
         

        

        

        
        <i class="fa fa-envelope fw"></i><a href="jethro.andersson02@gmail.com" target="_blank"> jethro.andersson02@gmail.com</a>
        

        

        <br>

        
        <i class="fa fa-linkedin fw"></i><a href="https://www.linkedin.com/in/jethro-andersson-apriliano-ofe" target="_blank"> jethro-andersson-apriliano-ofe</a>
        

        

        

        

<!--        
        <hr >
        <a href="https://stackoverflow.com/users/1473726?tab=profile">
           <img src="https://stackoverflow.com/users/flair/1473726.png?theme=clean" width="208" height="58" alt="profile for  at Stack Overflow, Q&amp;A for professional and enthusiast programmers" title="profile for  at Stack Overflow, Q&amp;A for professional and enthusiast programmers">
        </a>
        
        <hr >
        
        <p>You may also want to check this profile:
            <ul>
                
                  <li><a href=""></a></li>
                
            </ul>
        </p>
        
-->        
    </div>

</div>

                
              </div>
              <div class=" col-lg-8   col-sm-12 col-xs-12">
  <div class="row grid-content"> 
      <div class="col-md-12 col-xs-12 projet" style="margin-bottom:20px;">
          <p class="hidden-xs hidden-sm"><a href="http://localhost:4000/">Home</a> <span style="color:darkgrey"> / <a href="http://localhost:4000/data-science-1">data-science-1</a> / completing the square for normal model with multiple observations</span></p>
          <h3>Completing the Square for Normal Model with Multiple Observations<small class="pull-right"><a href="/feed.xml" target="_blank"><i class="fa fa-rss-square rss"></i></a></small><small class="pull-right"><a class="twitter-share-button" href="https://twitter.com/intent/tweet?via=&text=Equation (2.11) from BDA on page 42">Tweet</a></small></h3> 
          <!-- <hr>
              <p class="text-center">
               Completing the Square for Normal Model with Multiple Observations <br> 
                  <span class="text-small">Equation (2.11) from BDA on page 42</span> <br>
                  

              </p>
              <hr> -->

            <div class="entry">
              <p>The subchapter 2.5 of <a href="http://www.stat.columbia.edu/~gelman/book/BDA3.pdf"><strong>Bayesian Data Analysis Third Edition</strong></a> explains how to estimate a normal mean with known variance; particularly, the subchapter extends the development of a normal model with a single observation into the more realistic situation where <em>a sample of independent and identically distributed observations</em> $y = (y_1, \ldots, y_n)$ are available.</p>

<p><a href="/assets/images/normal-dist.jpg"><img src="/assets/images/normal-dist.jpg" alt="img1" class="img-responsive" /></a><em><center>$\pmb{\text{Figure 1}}$: Example of a normal distribution consisting a horde of rabbits. Image taken from <a href="https://vimeo.com/75089338">Casey Dunn</a>, some rights reserved.</center></em></p>

<p>The <em>posterior</em> density of the normal model consists of a <em>likelihood</em> distribution, $\Pr(y \mid \theta)$, and a <em>prior</em> distribution, $\Pr(\theta)$. Specifically,</p>

\[\begin{align}
	y_i \mid \theta &amp;\sim \text{N}(\theta, \sigma^2) &amp;&amp; \text{A normal distribution with mean = }\theta \text{ and variance = }\sigma^2\text{, for }i=1, \ldots, n \\
	\theta          &amp;\sim \text{N}(\mu_0, \tau_0^2)  &amp;&amp;  \text{A normal distribution with mean = }\mu_0 \text{ and variance = }\tau_0^2.
\end{align}\]

<p>Proceeding formally, the posterior density is</p>

<p>\(\begin{align}
\Pr(\theta \mid y) &amp;\propto \Pr(\theta) \Pr(y \mid \theta) &amp;&amp; \text{posterior definition} \tag{1}\label{eq:definition}\\
                   &amp;= \Pr(\theta) \prod_{i=1}^{n} \Pr(y_i \mid \theta) &amp;&amp; \text{i.i.d observations} \tag{2}\label{eq:iid} \\
                   &amp;\propto \exp \left( -\frac{1}{2 \tau_0^2} (\theta - \mu_0)^2 \right) \prod_{i=1}^n \exp \left( - \frac{1}{2 \sigma^2} (y_i - \theta)^2 \right) &amp;&amp; \text{normal distributions} \tag{3}\label{eq:exposition-normal} \\
                   &amp;= \exp \left( -\frac{1}{2} \left( \frac{1}{\tau_0^2} (\theta - \mu_0)^2 + \frac{1}{\sigma^2} \sum_{i=1}^{n} (y_i - \theta)^2 \right) \right)  &amp;&amp; \text{sum all terms} \tag{4}\label{eq:sum-all-terms} \\
                   &amp;= \exp \left( -\frac{1}{2} \left( \frac{1}{\tau_0^2} \theta^2 - \frac{2 \theta \mu_0}{\tau_0^2} + \frac{\mu_0^2}{\tau_0^2} + \frac{1}{\sigma^2} \sum_{i=1}^n (y_i^2 - 2 \theta y_i + \theta^2) \right) \right) &amp;&amp; \text{expand all squares} \tag{5}\label{eq:expand-all} \\
                   &amp;= \exp \left( -\frac{1}{2} \left( \frac{1}{\tau_0^2} \theta^2 - \frac{2 \theta \mu_0}{\tau_0^2} + \frac{\mu_0^2}{\tau_0^2} + \frac{\sum_{i=1}^n y_i^2}{\sigma^2} - \frac{2 \theta \sum_{i=1}^n y_i}{\sigma^2} + \frac{n \theta^2}{\sigma^2} \right) \right) &amp;&amp; \text{expand the last term} \tag{6}\label{eq:expand-again} \\
                   &amp;= \exp \left( -\frac{1}{2} \left( \frac{\theta^2}{\tau_0^2} + \frac{n \theta^2}{\sigma^2} - 2 \theta \left( \frac{\mu_0}{\tau_0^2} + \frac{\sum_{i=1}^n y_i}{\sigma^2} \right) + \frac{\mu_0^2}{\tau_0^2} + \frac{\sum_{i=1}^n y_i^2}{\sigma^2} \right) \right) &amp;&amp; \text{group all }\theta s \text{ &amp; } \theta^2 s \tag{7}\label{eq:collect-all} \\
                   &amp;= \exp \left( -\frac{1}{2} \left( \theta^2 \left( \frac{1}{\tau_0^2} + \frac{n}{\sigma^2} \right) - 2 \theta \left( \frac{\mu_0}{\tau_0^2} + \frac{\sum_{i=1}^n y_i}{\sigma^2} \right) + \frac{\mu_0^2}{\tau_0^2} + \frac{\sum_{i=1}^n y_i^2}{\sigma^2} \right) \times \frac{\frac{1}{\frac{1}{\tau_0^2} + \frac{n}{\sigma^2}}}{\frac{1}{\frac{1}{\tau_0^2} + \frac{n}{\sigma^2}}} \right) &amp;&amp; \text{use a trick} \tag{8}\label{eq:multiply-by} \\
                   &amp;= \exp \left( - \frac{1}{2} \frac{  \left( \theta^2 - 2 \theta \frac{ \frac{\mu_0}{\tau_0^2} + \frac{\sum y_i}{\sigma^2}}{ \frac{1}{\tau_0^2} + \frac{n}{\sigma^2}} + \frac{\frac{\mu_0^2}{\tau_0^2}}{\frac{1}{\tau_0^2} + \frac{n}{\sigma^2}}  + \frac{\frac{\sum y_i^2}{\sigma^2}}{\frac{1}{\tau_0^2} + \frac{n}{\sigma^2}} \right)  }{\frac{1}{\frac{1}{\tau_0^2} + \frac{n}{\sigma^2}}} \right) \tag{9}\label{eq:atas-bawah} \\
                   &amp;= \exp \left( - \frac{1}{2} \frac{\left( \theta - \frac{\frac{\mu_0}{\tau_0^2} + \frac{\sum y_i}{\sigma^2} }{ \frac{1}{\tau_0^2} + \frac{n}{\sigma^2}  }  \right)^2 + C}{\frac{1}{\frac{1}{\tau_0^2} + \frac{n}{\sigma^2}}}   \right) &amp;&amp; \text{with }C \text{ is a constant} \tag{10}\label{eq:a-constant} \\
                   &amp;\propto \exp \left( -\frac{1}{2} \frac{(\theta - \mu_n)^2}{\tau_n^2} \right) \tag{10}\label{eq:almost} \\
                   &amp;\propto \text{N}(\mu_n, \tau_n^2)  &amp;&amp; \text{a normal distribution}        \tag{11}\label{eq:finally}         
\end{align}\)
with</p>

<p>\(\begin{align}
	\mu_n &amp;= \frac{\frac{\mu_0}{\tau_0^2} + \frac{\sum_{i=1}^n y_i}{\sigma^2}}{\frac{1}{\tau_0^2} + \frac{n}{\sigma^2} } \tag{12}\label{eq:mu-n} \\
	      &amp;= \frac{\frac{\mu_0}{\tau_0^2} + \frac{n \bar{y}}{\sigma^2}}{\frac{1}{\tau_0^2} + \frac{n}{\sigma^2} } &amp;&amp; \text{because }\bar{y} = \frac{\sum_{i=1}^n y_i}{n} \tag{13}\label{eq:mu-n-2}
\end{align}\)
and</p>

\[\begin{equation}
	\frac{1}{\tau_n^2} = \frac{1}{\tau_0^2} + \frac{n}{\sigma^2}. \tag{14}\label{eq:sigma-n}
\end{equation}\]

<p>At last, we have shown that the <em>posterior</em> distribution of the normal model is also a normal distribution as it is explained by Equation (2.11) and (2.12) on page 42 of the <a href="http://www.stat.columbia.edu/~gelman/book/BDA3.pdf"><strong>book</strong></a>.</p>

            </div>
            <hr>
            <div class="date">
              Written on April 12, 2021
            </div>
            <br>
            
            
            
<div class="comments">
	<div id="disqus_thread"></div>
	<script type="text/javascript">

	    var disqus_shortname = 'jethroGIT-github-io';

	    (function() {
	        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	    })();

	</script>
	<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>


      </div>
  </div>


        </div>
      </div>
    </div>
    <script src="/assets/twitter.js"></script>
    
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" async
  src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

    
	<!-- Google Analytics -->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-27831864-1', 'auto');
		ga('send', 'pageview', {
		  'page': '/data-science-1/Completing_the_Square_for_Normal_Model/',
		  'title': 'Completing the Square for Normal Model with Multiple Observations'
		});
	</script>
	<!-- End Google Analytics -->


  </body>
</html>
